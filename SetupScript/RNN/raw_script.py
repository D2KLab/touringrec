# -*- coding: utf-8 -*-
"""LSTM(2hid)+FC_w2vec_great_1T%.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10vLRPRw0lEgtECmIO_Fep5timK9ef7T-
"""

from __future__ import unicode_literals, print_function, division
from io import open
import glob
import os
import torch
import torch.nn as nn
import random
import time
import math
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import numpy as np
import pandas as pd
#import csv
import sys as sys
from numpy import array
from numpy import argmax
from operator import itemgetter
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import normalize
from collections import defaultdict

torch.manual_seed(1)

def remove_single_actions(df):
  df = df.drop(df[(df['action_type'] == "clickout item") & (df['step'] == 1)].index)
  return df
  
def remove_test_single_actions(df_test, df_gt):
  df_sessions = df_test.groupby('session_id')

  for group_name, df_group in df_sessions:
    session_len = 0

    for action_index, action in df_group.iterrows():
      session_len = session_len + 1
    
    if session_len == 1:
      df_test = df_test.drop(df_test[df_test['session_id'] == action['session_id']].index)
      df_gt = df_gt.drop(df_gt[df_gt['session_id'] == action['session_id']].index)
      #df = df.drop(df[(df['action_type'] == "clickout item") & (df['step'] == 1)].index)
    
  return df_test, df_gt  
  
def remove_nonitem_actions(df):
  df = df.drop(df[(df['action_type'] != 'interaction item image') & (df['action_type'] != 'interaction item deals') & (df['action_type'] != 'clickout item') & (df['action_type'] != 'search for item')].index)
  return df

def reduce_df(df, dim):
  df = df.head(dim)
  return pd.DataFrame(df)

def get_corpus(df):
  session_id = ''
  temp_session = []
  splitted_sessions = []

  for action_index, action in df.iterrows():
    if session_id == '':
      session_id = action['session_id']

    if session_id != action['session_id']:
      splitted_sessions.append(temp_session)
      temp_session = []

    temp_session.append(action['reference'])
    session_id = action['session_id']

  return splitted_sessions

df_encode = pd.read_csv("./train_1.csv")
df_encode = remove_single_actions(df_encode)
df_encode = remove_nonitem_actions(df_encode)

df_encode = reduce_df(df_encode, 80000)

df_train = pd.read_csv("./train_1.csv")
df_train = remove_single_actions(df_train)
df_train =  remove_nonitem_actions(df_train)

df_train = reduce_df(df_train, 10000)


df_test = pd.read_csv("./test_1.csv")
df_test = remove_single_actions(df_test)
df_test = remove_nonitem_actions(df_test)

df_test = reduce_df(df_test, 1000)


df_gt = pd.read_csv("./gt_1.csv")

df_gt = reduce_df(df_gt, 1000)

df_test, df_gt = remove_test_single_actions(df_test, df_gt)

corpus = get_corpus(df_encode)

"""gensim trial"""

from gensim.models import Word2Vec

def normalize_word2vec(word2vec):
  hotels_pre_norm = []

  for hotel in word2vec.wv.index2word:
    hotels_pre_norm.append(word2vec.wv[hotel].tolist())

  hotels_pre_norm = np.asarray(hotels_pre_norm)
  hotels_post_norm = normalize(hotels_pre_norm, norm='l2', axis=0, copy=True, return_norm=False)
  
  hotels_post_norm = hotels_post_norm.tolist()

  for hotel in word2vec.wv.index2word:
    word2vec.wv[hotel] = np.asarray(hotels_post_norm[0])
    hotels_post_norm.pop(0)
    
  return word2vec

word2vec = Word2Vec(corpus, min_count=1, window=3, sg=1)

n_features = len(word2vec.wv['666856'])
n_features

word2vec.wv['666856']

#word2vec.wv.most_similar(positive = '4102552')

#hotel_dict = normalize_word2vec(word2vec.wv)
hotel_dict = word2vec.wv

word2vec.wv['666856']

n_hotels = len(hotel_dict.index2word)
n_features = len(word2vec.wv['666856'])

print('n_hotels is ' + str(n_hotels))
print('n_features is ' + str(n_features))

#preparing training data

#gets the training set and splits it in subsessions populated by the item of the action
def prepare_input(df_train):
  training_set = []
  category_set = []
  hotels_window_set = []
  
  df_sessions = df_train.groupby('session_id')

  for group_name, df_group in df_sessions:
    sub_sessions = []
    categories = []
    temp_session = []
    hotels_window = []

    for action_index, action in df_group.iterrows():
      if action['action_type'] == 'clickout item':
        sub_sessions.append(temp_session)
        temp_session.append(action)
        categories.append(action['reference'])
        hotels_window.append(action['impressions'].split('|'))
      else:
        temp_session.append(action)
        
    #training_set.concatenate(sub_sessions)
    #category_set.concatenate(categories)
    #hotels_window_set.concatenate(hotels_window)
    training_set = training_set + sub_sessions
    category_set = category_set + categories
    hotels_window_set = hotels_window_set + hotels_window
    
    
  return training_set, category_set, hotels_window_set

def recommendations_from_output(output, hotel_dict, hotels_window, n_features):
  i = 0
  window_dict = {}
  
  output_arr = np.asarray(output[0].cpu().detach().numpy())
    
  ranked_hotels = {}
  
  #for hotel_k, hotel_t in window_dict.items():
  #  d = distance(output, hotel_t)
  #  ranked_hotels[hotel_k] = d
  
  #hotel_scores = {}
  hotel_i = 0
  
  #print(len(output_arr))
  
  for hotel_v in output_arr:
    #print(hotel_v)
    hotel_id = hotel_dict.index2word[hotel_i]
    #print(hotel_id)
    #print(hotel_id)
    #print(hotels_window)
    if hotel_id in hotels_window:
      #print('found')
      ranked_hotels[hotel_id] = hotel_v
    hotel_i = hotel_i + 1
  
  for hotel_id in hotels_window:
    if hotel_id not in ranked_hotels:
      ranked_hotels[hotel_id] = 0
      #print('cant find ' + str(i) + ' sessions')
  
  #ranked_hotels = sorted(ranked_hotels)
  ranked_hotels = sorted(ranked_hotels.items(), key=itemgetter(1))
  #print(ranked_hotels)
  #print(hotels_window)
  #print(ranked_hotels)
  #print(list_to_space_string(ranked_hotels))
  ranked = []
  for tup in ranked_hotels:
    ranked.append(tup[0])
                           
                           
  return list_to_space_string(ranked)


# Just return an output given a line
def evaluate(session, hotel_dict, n_features, hotels_window):
    #hidden = rnn.initHidden()
    hidden = torch.zeros(1, 1, n_hidden)
    c = torch.zeros(1, 1, n_hidden)
    
    #print(session)
    line_tensor = session_to_tensor(session)
    for i in range(line_tensor.size()[0]):
      input = torch.zeros(1, 1, n_features)
      input[0][0] = line_tensor[i]
      input = input.cuda()
      output = model(input)
        
    #print(output)
    output = recommendations_from_output(output, hotel_dict, hotels_window, n_features)

    return output
  
def get_submission_target(df):
    """Identify target rows with missing click outs."""

    mask = df["reference"].isnull() & (df["action_type"] == "clickout item")
    df_out = df[mask]

    return df_out  

def get_reciprocal_ranks(ps):
    """Calculate reciprocal ranks for recommendations."""
    mask = ps.reference == np.array(ps.item_recommendations)

    if mask.sum() == 1:
        rranks = generate_rranks_range(0, len(ps.item_recommendations))
        return np.array(rranks)[mask].min()
    else:
        return 0.0


def score_submissions(subm_csv, gt_csv, objective_function):
    """Score submissions with given objective function."""

    #print(f"Reading ground truth data {gt_csv} ...")
    df_gt = read_into_df(gt_csv)

    #print(f"Reading submission data {subm_csv} ...")
    df_subm = read_into_df(subm_csv)

    # create dataframe containing the ground truth to target rows
    cols = ['reference', 'impressions', 'prices']
    df_key = df_gt.loc[:, cols]

    # append key to submission file
    df_subm_with_key = df_key.join(df_subm, how='inner')
    df_subm_with_key.reference = df_subm_with_key.reference.astype(int)
    df_subm_with_key = convert_string_to_list(
        df_subm_with_key, 'item_recommendations', 'item_recommendations'
    )

    # score each row
    df_subm_with_key['score'] = df_subm_with_key.apply(objective_function, axis=1)
    mrr = df_subm_with_key.score.mean()

    return mrr
  
def generate_rranks_range(start, end):
    """Generate reciprocal ranks for a given list length."""

    return 1.0 / (np.arange(start, end) + 1)
  
def convert_string_to_list(df, col, new_col):
    """Convert column from string to list format."""
    fxn = lambda arr_string: [int(item) for item in str(arr_string).split(" ")]

    mask = ~(df[col].isnull())

    df[new_col] = df[col]
    df.loc[mask, new_col] = df[mask][col].map(fxn)

    return df


def get_reciprocal_ranks(ps):
    """Calculate reciprocal ranks for recommendations."""
    mask = ps.reference == np.array(ps.item_recommendations)

    if mask.sum() == 1:
        rranks = generate_rranks_range(0, len(ps.item_recommendations))
        return np.array(rranks)[mask].min()
    else:
        return 0.0
  

def score_submissions_no_csv(df_subm, df_gt, objective_function):
    # create dataframe containing the ground truth to target rows
    cols = ['reference', 'impressions', 'prices']
    df_key = df_gt.loc[:, cols]

    # append key to submission file
    df_subm_with_key = df_key.join(df_subm, how='inner')
    df_subm_with_key.reference = df_subm_with_key.reference.astype(int)
    df_subm_with_key = convert_string_to_list(
        df_subm_with_key, 'item_recommendations', 'item_recommendations'
    )

    # score each row
    df_subm_with_key['score'] = df_subm_with_key.apply(objective_function, axis=1)
    mrr = df_subm_with_key.score.mean()

    return mrr
  
  
def test_accuracy(model, df_test, df_gt):
  df_test['item_recommendations'] = np.nan

  test_dim = len(df_test)
  temp_session = []
  hotels_window = []
  i = 0
  print_every = 500
  step = 0
  #df_result = pd.DataFrame(index = [0], columns=df_test.columns)
  #print(df_result)

  for action_index, action in df_test.iterrows():

    #print(action)
    #print('step ' + str(step))
    #print(len(temp_session)) 
    if(action['reference'] != 'unknown'):
      if (action['action_type'] == 'clickout item') & math.isnan(float(action['reference'])):
        hotels_window = action['impressions'].split('|')

        #print('window is ' + str(hotels_window))
        #print(len(temp_session)) 

        if len(temp_session) != 0:
          #print('doing sub')
          #print(evaluate(temp_session, hotel_dict, n_features, hotels_window, distance))
          df_test.loc[action_index, 'item_recommendations'] = evaluate(temp_session, hotel_dict, n_features, hotels_window)

        #print(p.o)
        temp_session.append(action)
        #print('added click')
      else:
        temp_session.append(action)
        #print(temp_session)
        #print('added action')

    if(i < test_dim-1):
      if action['session_id'] != df_test.iloc[[i + 1]]['session_id'].values[0]:
        step = 0
        #print(temp_session)
        #print(hotels_window)
        #print(p.r)
        temp_session = []
        hotels_window = []

    i = i+1  
    step = step + 1
    
    
  df_sub = get_submission_target(df_test)
  df_sub = df_sub[['user_id', 'session_id', 'timestamp','step', 'item_recommendations']]
  
  for action_index, action in df_gt.iterrows():
    if action_index not in df_sub.index.values.tolist():
      df_gt = df_gt.drop(action_index)

  mask = df_sub["item_recommendations"].notnull()
  df_sub = df_sub[mask]
  
  mrr = score_submissions_no_csv(df_sub, df_gt, get_reciprocal_ranks)
  return mrr

'''
STEP 3: CREATE MODEL CLASS
'''
 
class LSTMModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):
        super(LSTMModel, self).__init__()
        # Hidden dimensions
        self.hidden_dim = hidden_dim
         
        # Number of hidden layers
        self.layer_dim = layer_dim
               
        self.lstm = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, num_layers = layer_dim)  
        
        self.hidden_fc = nn.Linear(hidden_dim, hidden_dim * 2)
        
        self.fc = nn.Linear(hidden_dim * 2, output_dim)
    
    
    def forward(self, x):
        
        # Initialize hidden state with zeros
        #######################
        #  USE GPU FOR MODEL  #
        #######################
        #print(x.shape,"x.shape")100, 28, 28
        if torch.cuda.is_available():
            h0 = torch.zeros(self.layer_dim, x.size(1), self.hidden_dim).cuda()
        else:
            h0 = torch.zeros(self.layer_dim, x.size(1), self.hidden_dim)

        # Initialize cell state
        if torch.cuda.is_available():
            c0 = torch.zeros(self.layer_dim, x.size(1), self.hidden_dim).cuda()
        else:
            c0 = torch.zeros(self.layer_dim, x.size(1), hidden_dim)

        
        #cn = c0[0,:,:]
        #hn = h0[0,:,:]

        #for seq in range(x.size(1)):
        #    hn, cn = self.lstm(x[:,seq,:], (hn,cn)) 
        #    outs.append(hn)
            
        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))

        #out = self.fc(out)
        
        out = self.hidden_fc(out)
        
        out = out[-1, :, :]
        #out = out[]
        
        out = self.fc(out)
        
        #out = self.fc(out) 
        # out.size() --> 100, 10
        return out

input_dim = n_features
output_dim = n_hotels
hidden_dim = int(1/30 * (input_dim + output_dim))
print('hidden_dim is ' + str(hidden_dim))
layer_dim = 1
n_hidden = hidden_dim

model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)
model.lstm.weight_hh_l0.data.fill_(0)
x = 1
nn.init.uniform_(model.fc.weight, -x, x)
nn.init.uniform_(model.fc.bias, -x, x)
model = model.cuda()

#functions for training phase

def session_to_tensor(session):
  tensor = torch.zeros(len(session), 1, n_features)
  
  for ai, action in enumerate(session):
    tensor[ai][0] = hotel_to_tensor(action['reference'], hotel_dict, n_features)
  return tensor

def hotel_to_tensor(hotel, hotel_dict, n_features):
  tensor = torch.zeros(n_features)
  if hotel in hotel_dict: #-----------int
    tensor = torch.from_numpy(hotel_dict[hotel])
  return tensor

def hotel_to_category(hotel, hotel_dict, n_features):
  tensor = torch.zeros(1)

  if hotel in hotel_dict.index2word:
    tensor = torch.tensor([hotel_dict.index2word.index(hotel)], dtype=torch.long)

  
  return tensor

def category_from_output(output):
  top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data
  category_i = int(top_i[0][0])
  #print(output)
  return hotel_dict.index2word[category_i], category_i
  
  
def list_to_space_string(l):
  """Return a space separated string from a list"""
  s = " ".join(l)
  return s

loss_fn = torch.nn.CrossEntropyLoss().cuda()

learning_rate = 0.001
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

def train(category_tensor, line_tensor):
    hidden = torch.zeros(1, 1, n_hidden)
    c = torch.zeros(1, 1, n_hidden)
    
    optimizer.zero_grad()
    
    line_tensor = line_tensor.requires_grad_()
    line_tensor = line_tensor.cuda()
    

    output = model(line_tensor)
    
    category_tensor = category_tensor.long().cuda()

    loss = loss_fn(output, category_tensor)
    loss.backward()

    optimizer.step()
    
    return output, loss.item()

sessions, categories, hotels_window = prepare_input(df_train)

import time
import math

#distance = nn.PairwiseDistance(p=2., eps=1e-6)

num_epochs = 10

n_iters = len(sessions) * num_epochs
print_every = 100
plot_every = 1


# Keep track of losses for plotting
current_loss = 0
all_losses = []
all_acc = []

def timeSince(since):
    now = time.time()
    s = now - since
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)

start = time.time()

for epoch in range(1, num_epochs + 1):
  model.train()
  iter = 0
  
  #print('epoch ' + str(epoch))
  #print(str(len(sessions)) + ' sessions to be computed')
  
  for index, session in enumerate(sessions):
    iter = iter + 1

    session_tensor = session_to_tensor(session)
    category = categories[index]
    category_tensor = hotel_to_category(category, hotel_dict, n_hotels)

    
    output, loss = train(category_tensor, session_tensor)

    current_loss += loss
      
    if iter % print_every == 0:

        guess, guess_i = category_from_output(output)

        correct = '✓' if guess == category else '✗ (%s)' % category
        #print('(%s) %.4f %s / %s %s' % (timeSince(start), loss, session[0]['session_id'], guess, correct))

        
  # Add current loss avg to list of losses
  if epoch % plot_every == 0:
      all_losses.append(current_loss / (plot_every * len(sessions)))
      print('Epoch: ' + str(epoch) + ' Loss: ' + str(current_loss / (plot_every * len(sessions))))
      print('%d %d%% (%s)' % (epoch, epoch / num_epochs * 100, timeSince(start)))
      acc = test_accuracy(model, df_test, df_gt)
      print("Score: " + str(acc))
      all_acc.append(acc)
      current_loss = 0

import matplotlib.pyplot as plt
import matplotlib.ticker as ticker

plt.figure()
plt.plot(all_losses)

plt.figure()
plt.plot(all_acc)

all_losses

df_train

def recommendations_from_output(output, hotel_dict, hotels_window, n_features):
  i = 0
  window_dict = {}
  
  output_arr = np.asarray(output[0].cpu().detach().numpy())
    
  ranked_hotels = {}
  
  #for hotel_k, hotel_t in window_dict.items():
  #  d = distance(output, hotel_t)
  #  ranked_hotels[hotel_k] = d
  
  #hotel_scores = {}
  hotel_i = 0
  
  #print(len(output_arr))
  
  for hotel_v in output_arr:
    #print(hotel_v)
    hotel_id = hotel_dict.index2word[hotel_i]
    #print(hotel_id)
    #print(hotel_id)
    #print(hotels_window)
    if hotel_id in hotels_window:
      #print('found')
      ranked_hotels[hotel_id] = hotel_v
    hotel_i = hotel_i + 1
  
  for hotel_id in hotels_window:
    if hotel_id not in ranked_hotels:
      ranked_hotels[hotel_id] = 0
      #print('cant find ' + str(i) + ' sessions')
  
  #ranked_hotels = sorted(ranked_hotels)
  ranked_hotels = sorted(ranked_hotels.items(), key=itemgetter(1))
  #print(ranked_hotels)
  #print(hotels_window)
  #print(ranked_hotels)
  #print(list_to_space_string(ranked_hotels))
  ranked = []
  for tup in ranked_hotels:
    ranked.append(tup[0])
                           
                           
  return list_to_space_string(ranked)


# Just return an output given a line
def evaluate(session, hotel_dict, n_features, hotels_window):
    #hidden = rnn.initHidden()
    hidden = torch.zeros(1, 1, n_hidden)
    c = torch.zeros(1, 1, n_hidden)
    
    #print(session)
    line_tensor = session_to_tensor(session)
    for i in range(line_tensor.size()[0]):
      input = torch.zeros(1, 1, n_features)
      input[0][0] = line_tensor[i]
      input = input.cuda()
      output = model(input)
        
    #print(output)
    output = recommendations_from_output(output, hotel_dict, hotels_window, n_features)

    return output

df_test.iloc[[1]]['session_id'].values[0]

df_test['item_recommendations'] = np.nan

test_dim = len(df_test)
temp_session = []
hotels_window = []
i = 0
print_every = 500
step = 0
#df_result = pd.DataFrame(index = [0], columns=df_test.columns)
#print(df_result)

for action_index, action in df_test.iterrows():

  #print(action)
  #print('step ' + str(step))
  #print(len(temp_session)) 
  if(action['reference'] != 'unknown'):
    if (action['action_type'] == 'clickout item') & math.isnan(float(action['reference'])):
      hotels_window = action['impressions'].split('|')
      
      #print('window is ' + str(hotels_window))
      #print(len(temp_session)) 
      
      if len(temp_session) != 0:
        #print('doing sub')
        #print(evaluate(temp_session, hotel_dict, n_features, hotels_window, distance))
        df_test.loc[action_index, 'item_recommendations'] = evaluate(temp_session, hotel_dict, n_features, hotels_window)
        
      #print(p.o)
      temp_session.append(action)
      #print('added click')
    else:
      temp_session.append(action)
      #print(temp_session)
      #print('added action')
    
  if(i < test_dim-1):
    if action['session_id'] != df_test.iloc[[i + 1]]['session_id'].values[0]:
      step = 0
      #print(temp_session)
      #print(hotels_window)
      #print(p.r)
      temp_session = []
      hotels_window = []
    
  i = i+1  
  step = step + 1
    
  if i % print_every == 0:
    perc = (i / test_dim * 100)
    #print(str(perc) + '%')
    
#df_result.drop(df_result.head(1).index, inplace=True)

df_test[df_test['item_recommendations'] != np.nan]

#evaluate(temp_session, hotel_dict, n_features, hotels_window, distance)

def get_submission_target(df):
    """Identify target rows with missing click outs."""

    mask = df["reference"].isnull() & (df["action_type"] == "clickout item")
    df_out = df[mask]

    return df_out

#for action_index, action in df_sub.iterrows():
#  if type(action['item_recommendations']) is not str:
#  #if math.isnan(float(action['item_recommendations'])):
#    print(df_test[df_test['session_id'] == action['session_id']])
df_test[df_test['session_id'] == 'abc092e6a24e4']

df_test

df_test[df_test['action_type'] == 'clickout item']

df_sub = get_submission_target(df_test)

df_sub = df_sub[['user_id', 'session_id', 'timestamp','step', 'item_recommendations']]

df_sub

for action_index, action in df_gt.iterrows():
  if action_index not in df_sub.index.values.tolist():
    df_gt = df_gt.drop(action_index)
df_gt

word2vec.wv.most_similar(positive = '1319094')

mask = df_sub["item_recommendations"].notnull()
df_sub = df_sub[mask]

df_sub.to_csv('./sub_RNN.csv')

def get_reciprocal_ranks(ps):
    """Calculate reciprocal ranks for recommendations."""
    mask = ps.reference == np.array(ps.item_recommendations)

    if mask.sum() == 1:
        rranks = generate_rranks_range(0, len(ps.item_recommendations))
        return np.array(rranks)[mask].min()
    else:
        return 0.0


def score_submissions(subm_csv, gt_csv, objective_function):
    """Score submissions with given objective function."""

    #print(f"Reading ground truth data {gt_csv} ...")
    df_gt = read_into_df(gt_csv)

    #print(f"Reading submission data {subm_csv} ...")
    df_subm = read_into_df(subm_csv)

    # create dataframe containing the ground truth to target rows
    cols = ['reference', 'impressions', 'prices']
    df_key = df_gt.loc[:, cols]

    # append key to submission file
    df_subm_with_key = df_key.join(df_subm, how='inner')
    df_subm_with_key.reference = df_subm_with_key.reference.astype(int)
    df_subm_with_key = convert_string_to_list(
        df_subm_with_key, 'item_recommendations', 'item_recommendations'
    )

    # score each row
    df_subm_with_key['score'] = df_subm_with_key.apply(objective_function, axis=1)
    mrr = df_subm_with_key.score.mean()

    return mrr
  
def generate_rranks_range(start, end):
    """Generate reciprocal ranks for a given list length."""

    return 1.0 / (np.arange(start, end) + 1)
  
def convert_string_to_list(df, col, new_col):
    """Convert column from string to list format."""
    fxn = lambda arr_string: [int(item) for item in str(arr_string).split(" ")]

    mask = ~(df[col].isnull())

    df[new_col] = df[col]
    df.loc[mask, new_col] = df[mask][col].map(fxn)

    return df


def get_reciprocal_ranks(ps):
    """Calculate reciprocal ranks for recommendations."""
    mask = ps.reference == np.array(ps.item_recommendations)

    if mask.sum() == 1:
        rranks = generate_rranks_range(0, len(ps.item_recommendations))
        return np.array(rranks)[mask].min()
    else:
        return 0.0
  

def score_submissions_no_csv(df_subm, df_gt, objective_function):
    # create dataframe containing the ground truth to target rows
    cols = ['reference', 'impressions', 'prices']
    df_key = df_gt.loc[:, cols]

    # append key to submission file
    df_subm_with_key = df_key.join(df_subm, how='inner')
    df_subm_with_key.reference = df_subm_with_key.reference.astype(int)
    df_subm_with_key = convert_string_to_list(
        df_subm_with_key, 'item_recommendations', 'item_recommendations'
    )

    # score each row
    df_subm_with_key['score'] = df_subm_with_key.apply(objective_function, axis=1)
    mrr = df_subm_with_key.score.mean()

    return mrr

mrr = score_submissions_no_csv(df_sub, df_gt, get_reciprocal_ranks)
print("End execution with score " + str(mrr))