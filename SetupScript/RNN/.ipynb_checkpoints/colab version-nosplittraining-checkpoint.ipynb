{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0RMhmmDPERsJ",
    "outputId": "3ad7f889-79bb-4020-bac8-aad839efe077"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f646c06ab50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import csv\n",
    "import sys as sys\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from operator import itemgetter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import defaultdict\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-KBLBS8scoG"
   },
   "outputs": [],
   "source": [
    "def remove_single_actions(df):\n",
    "  df = df.drop(df[(df['action_type'] == \"clickout item\") & (df['step'] == 1)].index)\n",
    "  return df\n",
    "  \n",
    "def remove_test_single_actions(df_test, df_gt):\n",
    "  df_sessions = df_test.groupby('session_id')\n",
    "\n",
    "  for group_name, df_group in df_sessions:\n",
    "    session_len = 0\n",
    "\n",
    "    for action_index, action in df_group.iterrows():\n",
    "      session_len = session_len + 1\n",
    "    \n",
    "    if session_len == 1:\n",
    "      df_test = df_test.drop(df_test[df_test['session_id'] == action['session_id']].index)\n",
    "      df_gt = df_gt.drop(df_gt[df_gt['session_id'] == action['session_id']].index)\n",
    "      #df = df.drop(df[(df['action_type'] == \"clickout item\") & (df['step'] == 1)].index)\n",
    "    \n",
    "  return df_test, df_gt  \n",
    "  \n",
    "def remove_nonitem_actions(df):\n",
    "  df = df.drop(df[(df['action_type'] != 'interaction item image') & (df['action_type'] != 'interaction item deals') & (df['action_type'] != 'clickout item') & (df['action_type'] != 'search for item')].index)\n",
    "  return df\n",
    "\n",
    "def reduce_df(df, dim):\n",
    "  df = df.head(dim)\n",
    "  return pd.DataFrame(df)\n",
    "\n",
    "def get_corpus(df):\n",
    "  session_id = ''\n",
    "  temp_session = []\n",
    "  splitted_sessions = []\n",
    "  impressions = []\n",
    "\n",
    "  for action_index, action in df.iterrows():\n",
    "    if session_id == '':\n",
    "      session_id = action['session_id']\n",
    "\n",
    "    if session_id != action['session_id']:\n",
    "      splitted_sessions.append(temp_session)\n",
    "      splitted_sessions = splitted_sessions + impressions\n",
    "      temp_session = []\n",
    "      impressions = []\n",
    "\n",
    "    temp_session.append(action['reference'])\n",
    "    session_id = action['session_id']\n",
    "    \n",
    "    if action['action_type'] == 'clickout item':\n",
    "      impressions.append(action['impressions'].split('|')[:8])\n",
    "      \n",
    "\n",
    "  return splitted_sessions\n",
    "\n",
    "def generate_prices_sparse_matrix(df, features_col='intervals'):\n",
    "    df['present'] = 1\n",
    "    hotel_dict = create_item_dict(df) #Controllare che sia uguale all'altro dizionario\n",
    "    feature_dict = create_item_dict(df, col_name='feature')\n",
    "    list_hotel = list(df['reference'])\n",
    "    list_features = list(df['feature'])\n",
    "    list_data = list(df['present'])\n",
    "    n_items = len(list_hotel)\n",
    "    n_features = len(list_features)\n",
    "    # Convert each list of string in a list of indexes\n",
    "    list_items = list(map(lambda x: hotel_dict[x], list_hotel))\n",
    "    list_features = list(map(lambda x: feature_dict[x], list_features))\n",
    "    # Generate the sparse matrix\n",
    "    row = np.array(list_items)\n",
    "    col = np.array(list_features)\n",
    "    data = np.array(list_data)\n",
    "    csr = csr_matrix((data, (row, col)), shape=(n_items, n_features))\n",
    "\n",
    "    return csr, hotel_dict\n",
    "  \n",
    "def get_hotel_prices(df_metadata, n_categories = 2000):\n",
    "    \"\"\"\n",
    "    Required Input -\n",
    "        - metadata_file = file with the average price for each hotel\n",
    "    \"\"\"\n",
    "    #print(\"Reading metadata: \" + metadata_file)\n",
    "    df_metadata['price'] = df_metadata['price'].apply(lambda x: math.log10(x))\n",
    "    # Define the range\n",
    "    max_price = df_metadata['price'].max()\n",
    "    min_price = df_metadata['price'].min()\n",
    "    range = (max_price - min_price) / n_categories\n",
    "    # Generate the classes\n",
    "    df_metadata['intervals'] = pd.cut(df_metadata['price'], bins=np.arange(min_price,max_price,range))\n",
    "    df_metadata.loc[:, 'intervals'] = df_metadata['intervals'].apply(str)\n",
    "    #classes_dic = create_user_dict(df_metadata, col_name = 'intervals')\n",
    "    #df_metadata.loc[:, 'intervals'] = df_metadata['intervals'].apply(lambda x : classes_dic.get(x))\n",
    "    #df_metadata.loc[:, 'intervals'] = df_metadata['intervals'].apply(int)\n",
    "    # Create a dictionary of item_id -> price_category\n",
    "    price_dic = pd.Series(df_metadata.intervals.values,index=df_metadata.impressions).to_dict()\n",
    "\n",
    "\n",
    "    return price_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6pPZfTkIs6q1"
   },
   "outputs": [],
   "source": [
    "df_encode = pd.read_csv(\"./encode_1.csv\")\n",
    "df_encode = remove_single_actions(df_encode)\n",
    "df_encode = remove_nonitem_actions(df_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ulPfKUWI0C1Y",
    "outputId": "b7add39e-1b73-49c9-a93e-843c9654cbc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133689"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fw22j1XRz-7M"
   },
   "outputs": [],
   "source": [
    "#df_encode = reduce_df(df_encode, 80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65HWGa7utN5Z"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train_1.csv\")\n",
    "df_train = remove_single_actions(df_train)\n",
    "df_train =  remove_nonitem_actions(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5xZO_IH2nMPZ"
   },
   "outputs": [],
   "source": [
    "#df_train = reduce_df(df_train, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B7ZtycLjkT5O"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"./test_1.csv\")\n",
    "df_test = remove_single_actions(df_test)\n",
    "df_test = remove_nonitem_actions(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nllNorLakc-6"
   },
   "outputs": [],
   "source": [
    "#df_test = reduce_df(df_test, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veXr7Yn_kYMX"
   },
   "outputs": [],
   "source": [
    "df_gt = pd.read_csv(\"./gt_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_0E-SURPZJKh"
   },
   "outputs": [],
   "source": [
    "#df_gt = reduce_df(df_gt, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-KcWzPEaiNJ"
   },
   "outputs": [],
   "source": [
    "df_test, df_gt = remove_test_single_actions(df_test, df_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lKIyqyNve3zj"
   },
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(\"./item_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hme7KD8U7ELj"
   },
   "outputs": [],
   "source": [
    "df_prices = pd.read_csv(\"./hotel_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_Um-9fp7SJW"
   },
   "outputs": [],
   "source": [
    "price_dict = get_hotel_prices(df_prices, n_categories = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uOpDd4I47XdI",
    "outputId": "46aa941b-85c6-438e-9588-620998ae278d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(price_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pkIbI6AJoc9t"
   },
   "outputs": [],
   "source": [
    "corpus = get_corpus(df_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RaRTjAyA1Tll"
   },
   "source": [
    "gensim trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCOJdaNX1SnG"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KsskE6Fmn5fp"
   },
   "outputs": [],
   "source": [
    "def normalize_word2vec(word2vec):\n",
    "  hotels_pre_norm = []\n",
    "\n",
    "  for hotel in word2vec.wv.index2word:\n",
    "    hotels_pre_norm.append(word2vec.wv[hotel].tolist())\n",
    "\n",
    "  hotels_pre_norm = np.asarray(hotels_pre_norm)\n",
    "  hotels_post_norm = normalize(hotels_pre_norm, norm='l2', axis=0, copy=True, return_norm=False)\n",
    "  \n",
    "  hotels_post_norm = hotels_post_norm.tolist()\n",
    "\n",
    "  for hotel in word2vec.wv.index2word:\n",
    "    word2vec.wv[hotel] = np.asarray(hotels_post_norm[0])\n",
    "    hotels_post_norm.pop(0)\n",
    "    \n",
    "  return word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rNRRu4Ca1Vwl"
   },
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(corpus, min_count=1, window=3, sg=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z0_vaOJKXyPQ",
    "outputId": "aa6581db-8b26-4062-fcb9-f13921d41d1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = len(word2vec.wv['666856'])\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "bsMXQLL6fpWh",
    "outputId": "e523990f-7721-4c54-d464-e33f4f4258b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.43385236e-03, -5.85974567e-03,  5.68891130e-03,  2.70580947e-02,\n",
       "        1.29421921e-02,  2.66364329e-02, -8.32236721e-04,  1.46591952e-02,\n",
       "       -2.99845990e-02, -7.90513400e-03, -3.40466737e-03,  2.26807594e-02,\n",
       "       -1.98431052e-02,  1.89517569e-02,  1.93012320e-02,  3.63550469e-04,\n",
       "       -3.90568711e-02,  1.29658533e-02,  3.23108844e-02,  1.14307953e-02,\n",
       "        7.28571601e-03,  1.83826890e-02, -2.41642371e-02,  2.62602814e-03,\n",
       "        2.24970169e-02,  1.22538442e-02, -2.71763243e-02, -3.01339999e-02,\n",
       "       -3.05952989e-02,  4.40039113e-03,  5.37967728e-03,  4.52082109e-04,\n",
       "       -1.24047883e-02,  3.16534601e-02, -8.49470869e-03,  5.11352764e-03,\n",
       "       -1.89415533e-02,  7.47018377e-04,  5.26629388e-03,  7.59479590e-03,\n",
       "       -1.87180862e-02,  1.33755943e-02,  6.46037795e-03, -7.92148802e-03,\n",
       "       -1.96938310e-02,  1.94945000e-02,  2.76693050e-02,  1.03600519e-02,\n",
       "        1.77046936e-02, -4.33681570e-02, -1.98492501e-02,  2.74053053e-03,\n",
       "       -3.19321500e-03, -1.08704055e-02, -1.30935181e-02, -1.78803802e-02,\n",
       "        1.25532839e-02, -1.60536077e-02,  1.36448564e-02,  3.37791629e-02,\n",
       "        1.87711045e-02,  5.96802589e-03, -2.68120086e-03, -3.13814823e-03,\n",
       "       -4.70780674e-03, -1.01067219e-02,  1.66998096e-02,  1.99408513e-02,\n",
       "       -1.46050509e-02, -3.01174782e-02,  1.93775855e-02, -6.42216252e-03,\n",
       "        1.13377646e-02, -9.44079366e-03,  2.64676334e-03,  1.77647509e-02,\n",
       "       -2.10035890e-02, -5.01943473e-03, -2.31278791e-05,  2.85691116e-03,\n",
       "        1.83005426e-02, -4.89996094e-03, -1.03594055e-02,  1.84218697e-02,\n",
       "       -2.12039240e-02, -3.29295115e-04,  4.47795652e-02,  9.63853032e-04,\n",
       "       -3.24249454e-02,  2.38737836e-02,  1.56604778e-02,  2.29879352e-03,\n",
       "        2.49866936e-02,  1.41542032e-02,  3.79755236e-02, -1.03824388e-03,\n",
       "        1.32722454e-02, -1.66918617e-02,  4.69486648e-03,  2.06594244e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv['666856']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "6xrTXQvzQPYh",
    "outputId": "a5b0b812-19d1-4470-d7b4-a3ce2a588ccb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8242182', 0.9504700899124146),\n",
       " ('5502296', 0.9466519355773926),\n",
       " ('6785', 0.943709135055542),\n",
       " ('1369270', 0.9411848783493042),\n",
       " ('101932', 0.9406952261924744),\n",
       " ('44355', 0.9406229257583618),\n",
       " ('5050642', 0.9405085444450378),\n",
       " ('5104290', 0.9395586252212524),\n",
       " ('2805646', 0.9393075704574585),\n",
       " ('4493122', 0.9390658736228943)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(positive = '4102552')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6M6sw8hc3rg"
   },
   "outputs": [],
   "source": [
    "#hotel_dict = normalize_word2vec(word2vec.wv)\n",
    "hotel_dict = word2vec.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "QKIUd1Rg4PSI",
    "outputId": "16d87fd1-0408-4226-b390-a68a1f824c41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.43385236e-03, -5.85974567e-03,  5.68891130e-03,  2.70580947e-02,\n",
       "        1.29421921e-02,  2.66364329e-02, -8.32236721e-04,  1.46591952e-02,\n",
       "       -2.99845990e-02, -7.90513400e-03, -3.40466737e-03,  2.26807594e-02,\n",
       "       -1.98431052e-02,  1.89517569e-02,  1.93012320e-02,  3.63550469e-04,\n",
       "       -3.90568711e-02,  1.29658533e-02,  3.23108844e-02,  1.14307953e-02,\n",
       "        7.28571601e-03,  1.83826890e-02, -2.41642371e-02,  2.62602814e-03,\n",
       "        2.24970169e-02,  1.22538442e-02, -2.71763243e-02, -3.01339999e-02,\n",
       "       -3.05952989e-02,  4.40039113e-03,  5.37967728e-03,  4.52082109e-04,\n",
       "       -1.24047883e-02,  3.16534601e-02, -8.49470869e-03,  5.11352764e-03,\n",
       "       -1.89415533e-02,  7.47018377e-04,  5.26629388e-03,  7.59479590e-03,\n",
       "       -1.87180862e-02,  1.33755943e-02,  6.46037795e-03, -7.92148802e-03,\n",
       "       -1.96938310e-02,  1.94945000e-02,  2.76693050e-02,  1.03600519e-02,\n",
       "        1.77046936e-02, -4.33681570e-02, -1.98492501e-02,  2.74053053e-03,\n",
       "       -3.19321500e-03, -1.08704055e-02, -1.30935181e-02, -1.78803802e-02,\n",
       "        1.25532839e-02, -1.60536077e-02,  1.36448564e-02,  3.37791629e-02,\n",
       "        1.87711045e-02,  5.96802589e-03, -2.68120086e-03, -3.13814823e-03,\n",
       "       -4.70780674e-03, -1.01067219e-02,  1.66998096e-02,  1.99408513e-02,\n",
       "       -1.46050509e-02, -3.01174782e-02,  1.93775855e-02, -6.42216252e-03,\n",
       "        1.13377646e-02, -9.44079366e-03,  2.64676334e-03,  1.77647509e-02,\n",
       "       -2.10035890e-02, -5.01943473e-03, -2.31278791e-05,  2.85691116e-03,\n",
       "        1.83005426e-02, -4.89996094e-03, -1.03594055e-02,  1.84218697e-02,\n",
       "       -2.12039240e-02, -3.29295115e-04,  4.47795652e-02,  9.63853032e-04,\n",
       "       -3.24249454e-02,  2.38737836e-02,  1.56604778e-02,  2.29879352e-03,\n",
       "        2.49866936e-02,  1.41542032e-02,  3.79755236e-02, -1.03824388e-03,\n",
       "        1.32722454e-02, -1.66918617e-02,  4.69486648e-03,  2.06594244e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv['666856']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEz4ZPy8p1gF"
   },
   "outputs": [],
   "source": [
    "#preparing training data\n",
    "\n",
    "#gets the training set and splits it in subsessions populated by the item of the action\n",
    "def prepare_input(df_train):\n",
    "  training_set = []\n",
    "  category_set = []\n",
    "  hotels_window_set = []\n",
    "  \n",
    "  df_sessions = df_train.groupby('session_id')\n",
    "\n",
    "  for group_name, df_group in df_sessions:\n",
    "    sub_sessions = []\n",
    "    categories = []\n",
    "    temp_session = []\n",
    "    hotels_window = []\n",
    "\n",
    "    for action_index, action in df_group.iterrows():\n",
    "      if action['action_type'] == 'clickout item':\n",
    "        sub_sessions.append(temp_session)\n",
    "        temp_session.append(action)\n",
    "        categories.append(action['reference'])\n",
    "        hotels_window.append(action['impressions'].split('|'))\n",
    "      else:\n",
    "        temp_session.append(action)\n",
    "        \n",
    "    #training_set.concatenate(sub_sessions)\n",
    "    #category_set.concatenate(categories)\n",
    "    #hotels_window_set.concatenate(hotels_window)\n",
    "    training_set = training_set + sub_sessions\n",
    "    category_set = category_set + categories\n",
    "    hotels_window_set = hotels_window_set + hotels_window\n",
    "    \n",
    "    \n",
    "  return training_set, category_set, hotels_window_set\n",
    "\n",
    "#gets the training set and splits it in subsessions populated by the item of the action\n",
    "def prepare_input_batched(df_train, batch_size):\n",
    "  training_set = []\n",
    "  category_set = []\n",
    "  hotels_window_set = []\n",
    "\n",
    "  training_set_batched = []\n",
    "  category_set_batched = []\n",
    "  hotels_window_set_batched = []\n",
    "\n",
    "  df_sessions = df_train.groupby('session_id')\n",
    "\n",
    "  for group_name, df_group in df_sessions:\n",
    "    sub_sessions = []\n",
    "    categories = []\n",
    "    temp_session = []\n",
    "    hotels_window = []\n",
    "\n",
    "    for action_index, action in df_group.iterrows():\n",
    "      if action['action_type'] == 'clickout item':\n",
    "        sub_sessions.append(temp_session)\n",
    "        temp_session.append(action)\n",
    "        categories.append(action['reference'])\n",
    "        hotels_window.append(action['impressions'].split('|'))\n",
    "      else:\n",
    "        temp_session.append(action)\n",
    "        \n",
    "    #training_set.concatenate(sub_sessions)\n",
    "    #category_set.concatenate(categories)\n",
    "    #hotels_window_set.concatenate(hotels_window)\n",
    "    training_set = training_set + sub_sessions\n",
    "    category_set = category_set + categories\n",
    "    hotels_window_set = hotels_window_set + hotels_window\n",
    "  \n",
    "  temp_session_batched = []\n",
    "  temp_category_batched = []\n",
    "  temp_hotel_window_batched = []\n",
    "  \n",
    "  for si, session in enumerate(training_set):\n",
    "    temp_session_batched.append(session)\n",
    "    temp_category_batched.append(category_set[si])\n",
    "    temp_hotel_window_batched.append(hotels_window_set[si])\n",
    "  \n",
    "    if len(temp_session_batched) == batch_size:\n",
    "      training_set_batched.append(temp_session_batched)\n",
    "      category_set_batched.append(temp_category_batched)\n",
    "      hotels_window_set_batched.append(temp_hotel_window_batched)\n",
    "      temp_session_batched = []\n",
    "      temp_category_batched = []\n",
    "      temp_hotel_window_batched = []\n",
    "\n",
    "  if len(temp_session_batched) != 0:\n",
    "    training_set_batched.append(temp_session_batched)\n",
    "    category_set_batched.append(temp_category_batched)\n",
    "    hotels_window_set_batched.append(temp_hotel_window_batched)\n",
    "    \n",
    "    \n",
    "  return training_set_batched, category_set_batched, hotels_window_set_batched\n",
    "\n",
    "def prepare_test(df_test, df_gt):\n",
    "  #Creating a NaN column for item recommendations\n",
    "  df_test['item_recommendations'] = np.nan\n",
    "\n",
    "  test_dim = len(df_test)\n",
    "\n",
    "  temp_session = []\n",
    "  test_sessions = []\n",
    "\n",
    "  temp_clickout_index = []\n",
    "  test_clickout_index = []\n",
    "\n",
    "  temp_hotels_window = []\n",
    "  test_hotels_window = []\n",
    "\n",
    "  i = 0\n",
    "  step = 0\n",
    "\n",
    "  #splitting in sessions while evaluating recommendations for NaN clickouts\n",
    "  for action_index, action in df_test.iterrows():\n",
    "      if(action['reference'] != 'unknown'):\n",
    "          if (action['action_type'] == 'clickout item') & math.isnan(float(action['reference'])):\n",
    "              temp_hotels_window = action['impressions'].split('|')\n",
    "              temp_session.append(action)\n",
    "              temp_clickout_index.append(action_index)\n",
    "          else:\n",
    "              temp_session.append(action)\n",
    "\n",
    "      if(i < test_dim-1):\n",
    "          if action['session_id'] != df_test.iloc[[i + 1]]['session_id'].values[0]:\n",
    "              step = 0\n",
    "              test_sessions.append(temp_session)\n",
    "              test_hotels_window.append(temp_hotels_window)\n",
    "              test_clickout_index.append(temp_clickout_index)\n",
    "              temp_session = []\n",
    "              temp_hotels_window = []\n",
    "              temp_clickout_index = []\n",
    "\n",
    "\n",
    "      i = i+1  \n",
    "      step = step + 1\n",
    "        \n",
    "  return test_sessions, test_hotels_window, test_clickout_index\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OUCoyd8mA_k2"
   },
   "outputs": [],
   "source": [
    "def recommendations_from_output(output, hotel_dict, hotels_window, n_features):\n",
    "  i = 0\n",
    "  window_dict = {}\n",
    "  \n",
    "  output_arr = np.asarray(output[0].cpu().detach().numpy())\n",
    "    \n",
    "  ranked_hotels = {}\n",
    "  \n",
    "  #for hotel_k, hotel_t in window_dict.items():\n",
    "  #  d = distance(output, hotel_t)\n",
    "  #  ranked_hotels[hotel_k] = d\n",
    "  \n",
    "  #hotel_scores = {}\n",
    "  hotel_i = 0\n",
    "  missed = 0\n",
    "  #print(len(output_arr))\n",
    "  \n",
    "  for hotel_v in output_arr:\n",
    "    #print(hotel_v)\n",
    "    hotel_id = hotel_dict.index2word[hotel_i]\n",
    "    #print(hotel_id)\n",
    "    #print(hotel_id)\n",
    "    #print(hotels_window)\n",
    "    if hotel_id in hotels_window:\n",
    "      #print('found')\n",
    "      ranked_hotels[hotel_id] = hotel_v\n",
    "    hotel_i = hotel_i + 1\n",
    "  \n",
    "  for hotel_id in hotels_window:\n",
    "    if hotel_id not in ranked_hotels:\n",
    "      ranked_hotels[hotel_id] = -999999\n",
    "      #print(hotel_id)\n",
    "      missed = missed + 1\n",
    "  #print(str(len(hotels_window)) + ' - ' + str(missed))\n",
    "\n",
    "  #ranked_hotels = sorted(ranked_hotels)\n",
    "  ranked_hotels = sorted(ranked_hotels.items(), key=itemgetter(1), reverse = True)\n",
    "  #print(ranked_hotels)\n",
    "  #print(hotels_window)\n",
    "  #print(ranked_hotels)\n",
    "  #print(list_to_space_string(ranked_hotels))\n",
    "  ranked = []\n",
    "  for tup in ranked_hotels:\n",
    "    ranked.append(tup[0])\n",
    "    \n",
    "  #print(ranked_hotels)\n",
    "                           \n",
    "                           \n",
    "  return list_to_space_string(ranked)\n",
    "\n",
    "\n",
    "# Just return an output given a line\n",
    "def evaluate(session, hotel_dict, n_features, hotels_window, max_window):\n",
    "    #hidden = rnn.initHidden()\n",
    "    hidden = torch.zeros(1, 1, n_hidden)\n",
    "    c = torch.zeros(1, 1, n_hidden)\n",
    "    \n",
    "    #print(session)\n",
    "    #print(max_window)\n",
    "    line_tensor = session_to_tensor(session, hotels_window, max_window).cuda()\n",
    "    \n",
    "    output = model(line_tensor)\n",
    "        \n",
    "    #print(output)\n",
    "    output = recommendations_from_output(output, hotel_dict, hotels_window, n_features)\n",
    "\n",
    "    return output\n",
    "  \n",
    "  \n",
    "def recommendations_from_output_debug(output, hotel_dict, hotels_window, n_features):\n",
    "  i = 0\n",
    "  window_dict = {}\n",
    "  \n",
    "  output_arr = np.asarray(output[0].cpu().detach().numpy())\n",
    "    \n",
    "  ranked_hotels = {}\n",
    "  \n",
    "  #for hotel_k, hotel_t in window_dict.items():\n",
    "  #  d = distance(output, hotel_t)\n",
    "  #  ranked_hotels[hotel_k] = d\n",
    "  \n",
    "  #hotel_scores = {}\n",
    "  hotel_i = 0\n",
    "  \n",
    "  print(len(output_arr))\n",
    "  print(hotels_window)\n",
    "  \n",
    "  for hotel_index, hotel_v in enumerate(output_arr):\n",
    "    #print(hotel_v)\n",
    "    hotel_id = hotel_dict.index2word[hotel_index]\n",
    "    #print(hotel_id)\n",
    "    #print(hotel_id)\n",
    "    #print(hotels_window)\n",
    "    if hotel_id in hotels_window:\n",
    "      #print('found')\n",
    "      ranked_hotels[hotel_id] = hotel_v\n",
    "    hotel_i = hotel_i + 1\n",
    "  \n",
    "  for hotel_id in hotels_window:\n",
    "    if hotel_id not in ranked_hotels:\n",
    "      ranked_hotels[hotel_id] = -999999\n",
    "      print('cant find ' + str(i) + ' sessions')\n",
    "  \n",
    "  #ranked_hotels = sorted(ranked_hotels)\n",
    "  ranked_hotels = sorted(ranked_hotels.items(), key=itemgetter(1), reverse = True)\n",
    "  #print(ranked_hotels)\n",
    "  #print(hotels_window)\n",
    "  #print(ranked_hotels)\n",
    "  #print(list_to_space_string(ranked_hotels))\n",
    "  ranked = []\n",
    "  for tup in ranked_hotels:\n",
    "    ranked.append(tup[0])\n",
    "    \n",
    "  print(ranked_hotels)\n",
    "                           \n",
    "                           \n",
    "  return list_to_space_string(ranked)\n",
    "  \n",
    "def evaluate_debug(session, hotel_dict, n_features, hotels_window, max_window):\n",
    "    #hidden = rnn.initHidden()\n",
    "    hidden = torch.zeros(1, 1, n_hidden)\n",
    "    c = torch.zeros(1, 1, n_hidden)\n",
    "    \n",
    "    #print(session)\n",
    "    #print(max_window)\n",
    "    line_tensor = session_to_tensor(session, hotels_window, max_window).cuda()\n",
    "    print(line_tensor)\n",
    "\n",
    "    output = model(line_tensor)\n",
    "        \n",
    "    print(output)\n",
    "    output = recommendations_from_output_debug(output, hotel_dict, hotels_window, n_features)\n",
    "\n",
    "    return output\n",
    "  \n",
    "def recommendations_from_output_debug_false(output, hotel_dict, hotels_window, n_features):\n",
    "  i = 0\n",
    "  window_dict = {}\n",
    "  \n",
    "  output_arr = np.asarray(output[0].cpu().detach().numpy())\n",
    "    \n",
    "  ranked_hotels = {}\n",
    "  \n",
    "  #for hotel_k, hotel_t in window_dict.items():\n",
    "  #  d = distance(output, hotel_t)\n",
    "  #  ranked_hotels[hotel_k] = d\n",
    "  \n",
    "  #hotel_scores = {}\n",
    "  hotel_i = 0\n",
    "  \n",
    "  print(len(output_arr))\n",
    "  print(hotels_window)\n",
    "  \n",
    "  for hotel_index, hotel_v in enumerate(output_arr):\n",
    "    #print(hotel_v)\n",
    "    hotel_id = hotel_dict.index2word[hotel_index]\n",
    "    #print(hotel_id)\n",
    "    #print(hotel_id)\n",
    "    #print(hotels_window)\n",
    "    if hotel_id in hotels_window:\n",
    "      #print('found')\n",
    "      ranked_hotels[hotel_id] = hotel_v\n",
    "    hotel_i = hotel_i + 1\n",
    "  \n",
    "  for hotel_id in hotels_window:\n",
    "    if hotel_id not in ranked_hotels:\n",
    "      ranked_hotels[hotel_id] = 0\n",
    "      #print('cant find ' + str(i) + ' sessions')\n",
    "  \n",
    "  #ranked_hotels = sorted(ranked_hotels)\n",
    "  ranked_hotels = sorted(ranked_hotels.items(), key=itemgetter(1), reverse = False)\n",
    "  #print(ranked_hotels)\n",
    "  #print(hotels_window)\n",
    "  #print(ranked_hotels)\n",
    "  #print(list_to_space_string(ranked_hotels))\n",
    "  ranked = []\n",
    "  for tup in ranked_hotels:\n",
    "    ranked.append(tup[0])\n",
    "    \n",
    "  print(ranked_hotels)\n",
    "                           \n",
    "                           \n",
    "  return list_to_space_string(ranked)\n",
    "  \n",
    "def evaluate_debug_false(session, hotel_dict, n_features, hotels_window, max_window):\n",
    "    #hidden = rnn.initHidden()\n",
    "    hidden = torch.zeros(1, 1, n_hidden)\n",
    "    c = torch.zeros(1, 1, n_hidden)\n",
    "    \n",
    "    #print(session)\n",
    "    #print(max_window)\n",
    "    line_tensor = session_to_tensor(session, hotels_window, max_window).cuda()\n",
    "    output = model(line_tensor)\n",
    "        \n",
    "    print(output)\n",
    "    output = recommendations_from_output_debug_false(output, hotel_dict, hotels_window, n_features)\n",
    "\n",
    "    return output\n",
    "  \n",
    "def get_submission_target(df):\n",
    "    \"\"\"Identify target rows with missing click outs.\"\"\"\n",
    "\n",
    "    mask = df[\"reference\"].isnull() & (df[\"action_type\"] == \"clickout item\")\n",
    "    df_out = df[mask]\n",
    "\n",
    "    return df_out  \n",
    "\n",
    "def get_reciprocal_ranks(ps):\n",
    "    \"\"\"Calculate reciprocal ranks for recommendations.\"\"\"\n",
    "    mask = ps.reference == np.array(ps.item_recommendations)\n",
    "\n",
    "    if mask.sum() == 1:\n",
    "        rranks = generate_rranks_range(0, len(ps.item_recommendations))\n",
    "        return np.array(rranks)[mask].min()\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def score_submissions(subm_csv, gt_csv, objective_function):\n",
    "    \"\"\"Score submissions with given objective function.\"\"\"\n",
    "\n",
    "    print(f\"Reading ground truth data {gt_csv} ...\")\n",
    "    df_gt = read_into_df(gt_csv)\n",
    "\n",
    "    print(f\"Reading submission data {subm_csv} ...\")\n",
    "    df_subm = read_into_df(subm_csv)\n",
    "\n",
    "    # create dataframe containing the ground truth to target rows\n",
    "    cols = ['reference', 'impressions', 'prices']\n",
    "    df_key = df_gt.loc[:, cols]\n",
    "\n",
    "    # append key to submission file\n",
    "    df_subm_with_key = df_key.join(df_subm, how='inner')\n",
    "    df_subm_with_key.reference = df_subm_with_key.reference.astype(int)\n",
    "    df_subm_with_key = convert_string_to_list(\n",
    "        df_subm_with_key, 'item_recommendations', 'item_recommendations'\n",
    "    )\n",
    "\n",
    "    # score each row\n",
    "    df_subm_with_key['score'] = df_subm_with_key.apply(objective_function, axis=1)\n",
    "    mrr = df_subm_with_key.score.mean()\n",
    "\n",
    "    return mrr\n",
    "  \n",
    "def generate_rranks_range(start, end):\n",
    "    \"\"\"Generate reciprocal ranks for a given list length.\"\"\"\n",
    "\n",
    "    return 1.0 / (np.arange(start, end) + 1)\n",
    "  \n",
    "def convert_string_to_list(df, col, new_col):\n",
    "    \"\"\"Convert column from string to list format.\"\"\"\n",
    "    fxn = lambda arr_string: [int(item) for item in str(arr_string).split(\" \")]\n",
    "\n",
    "    mask = ~(df[col].isnull())\n",
    "\n",
    "    df[new_col] = df[col]\n",
    "    df.loc[mask, new_col] = df[mask][col].map(fxn)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_reciprocal_ranks(ps):\n",
    "    \"\"\"Calculate reciprocal ranks for recommendations.\"\"\"\n",
    "    mask = ps.reference == np.array(ps.item_recommendations)\n",
    "\n",
    "    if mask.sum() == 1:\n",
    "        rranks = generate_rranks_range(0, len(ps.item_recommendations))\n",
    "        return np.array(rranks)[mask].min()\n",
    "    else:\n",
    "        return 0.0\n",
    "  \n",
    "\n",
    "def score_submissions_no_csv(df_subm, df_gt, objective_function):\n",
    "    # create dataframe containing the ground truth to target rows\n",
    "    cols = ['reference', 'impressions', 'prices']\n",
    "    df_key = df_gt.loc[:, cols]\n",
    "\n",
    "    # append key to submission file\n",
    "    df_subm_with_key = df_key.join(df_subm, how='inner')\n",
    "    df_subm_with_key.reference = df_subm_with_key.reference.astype(int)\n",
    "    df_subm_with_key = convert_string_to_list(\n",
    "        df_subm_with_key, 'item_recommendations', 'item_recommendations'\n",
    "    )\n",
    "\n",
    "    # score each row\n",
    "    df_subm_with_key['score'] = df_subm_with_key.apply(objective_function, axis=1)\n",
    "    mrr = df_subm_with_key.score.mean()\n",
    "\n",
    "    return mrr\n",
    "  \n",
    "  \n",
    "def test_accuracy(model, df_test, df_gt):\n",
    "  df_test['item_recommendations'] = np.nan\n",
    "\n",
    "  test_dim = len(df_test)\n",
    "  temp_session = []\n",
    "  hotels_window = []\n",
    "  i = 0\n",
    "  print_every = 500\n",
    "  step = 0\n",
    "  #df_result = pd.DataFrame(index = [0], columns=df_test.columns)\n",
    "  #print(df_result)\n",
    "\n",
    "  for action_index, action in df_test.iterrows():\n",
    "\n",
    "    #print(action)\n",
    "    #print('step ' + str(step))\n",
    "    #print(len(temp_session)) \n",
    "    if(action['reference'] != 'unknown'):\n",
    "      if (action['action_type'] == 'clickout item') & math.isnan(float(action['reference'])):\n",
    "        hotels_window = action['impressions'].split('|')\n",
    "\n",
    "        #print('window is ' + str(hotels_window))\n",
    "        #print(len(temp_session)) \n",
    "\n",
    "        if len(temp_session) != 0:\n",
    "          #print('doing sub')\n",
    "          #print(evaluate(temp_session, hotel_dict, n_features, hotels_window, distance))\n",
    "          df_test.loc[action_index, 'item_recommendations'] = evaluate(temp_session, hotel_dict, n_features, hotels_window, max_window)\n",
    "        #print(p.o)\n",
    "        temp_session.append(action)\n",
    "        #print('added click')\n",
    "      else:\n",
    "        temp_session.append(action)\n",
    "        #print(temp_session)\n",
    "        #print('added action')\n",
    "\n",
    "    if(i < test_dim-1):\n",
    "      if action['session_id'] != df_test.iloc[[i + 1]]['session_id'].values[0]:\n",
    "        step = 0\n",
    "        #print(temp_session)\n",
    "        #print(hotels_window)\n",
    "        #print(p.r)\n",
    "        temp_session = []\n",
    "        hotels_window = []\n",
    "\n",
    "    i = i+1  \n",
    "    step = step + 1\n",
    "    \n",
    "    \n",
    "  df_sub = get_submission_target(df_test)\n",
    "  df_sub = df_sub[['user_id', 'session_id', 'timestamp','step', 'item_recommendations']]\n",
    "  \n",
    "  for action_index, action in df_gt.iterrows():\n",
    "    if action_index not in df_sub.index.values.tolist():\n",
    "      df_gt = df_gt.drop(action_index)\n",
    "\n",
    "  mask = df_sub[\"item_recommendations\"].notnull()\n",
    "  df_sub = df_sub[mask]\n",
    "  \n",
    "  mrr = score_submissions_no_csv(df_sub, df_gt, get_reciprocal_ranks)\n",
    "  return mrr\n",
    "\n",
    "def test_accuracy_optimized(model, df_test, df_gt, sessions, hotels_window, clickout_index, hotel_dict, n_features, max_window, meta_dict, meta_list, subname=\"submission_default_name\", isprint=False):\n",
    "  \"\"\"Return the score obtained by the net on the test dataframe\"\"\"\n",
    "\n",
    "  test_dim = len(df_test)\n",
    "\n",
    "  print_every = 500\n",
    "  \n",
    "  missed_target = 0\n",
    "\n",
    "  for session_index, session in enumerate(sessions):\n",
    "    if clickout_index[session_index] != []:\n",
    "      df_test.loc[clickout_index[session_index], 'item_recommendations'] = evaluate(session, hotel_dict, n_features, hotels_window[session_index], max_window)\n",
    "      #print(df_gt[(df_gt['session_id'] == df_test.loc[clickout_index[session_index], 'session_id'].values[0]) & (df_gt['step'] == df_test.loc[clickout_index[session_index], 'step'].values[0])]['reference'].values[0])\n",
    "      #target = df_gt[(df_gt['session_id'] == df_test.loc[clickout_index[session_index], 'session_id'].values[0]) & (df_gt['step'] == df_test.loc[clickout_index[session_index], 'step'].values[0])]['reference'].values[0]\n",
    "      #print(type(target))\n",
    "      #if int(target) not in hotel_dict: \n",
    "        #missed_target = missed_target + 1\n",
    "        #print(session_index)\n",
    "  df_sub = get_submission_target(df_test)\n",
    "\n",
    "  print(str(missed_target) + ' correct hotels were not in dictionary - total: ' + str(len(hotels_window)))\n",
    "  \n",
    "  #Removing unnecessary columns\n",
    "  df_sub = df_sub[['user_id', 'session_id', 'timestamp','step', 'item_recommendations']]\n",
    "\n",
    "  mask = df_sub[\"item_recommendations\"].notnull()\n",
    "  df_sub = df_sub[mask]\n",
    "\n",
    "  # Saving df_sub\n",
    "  if isprint:\n",
    "      df_sub.to_csv('./' + subname + '.csv')\n",
    "\n",
    "  mrr = score_submissions_no_csv(df_sub, df_gt, get_reciprocal_ranks)\n",
    "  return mrr\n",
    "\n",
    "\n",
    "def test_accuracy_optimized_false(model, df_test, df_gt, sessions, hotels_window, clickout_index, hotel_dict, n_features, max_window, meta_dict, meta_list, subname=\"submission_default_name\", isprint=False):\n",
    "  \"\"\"Return the score obtained by the net on the test dataframe\"\"\"\n",
    "\n",
    "  test_dim = len(df_test)\n",
    "\n",
    "  print_every = 500\n",
    "\n",
    "\n",
    "  for session_index, session in enumerate(sessions):\n",
    "    if clickout_index[session_index] != []:\n",
    "      df_test.loc[clickout_index[session_index], 'item_recommendations'] = evaluate_debug_false(session, hotel_dict, n_features, hotels_window[session_index], max_window)\n",
    "      #print(session_index)\n",
    "  df_sub = get_submission_target(df_test)\n",
    "\n",
    "  #Removing unnecessary columns\n",
    "  df_sub = df_sub[['user_id', 'session_id', 'timestamp','step', 'item_recommendations']]\n",
    "\n",
    "  mask = df_sub[\"item_recommendations\"].notnull()\n",
    "  df_sub = df_sub[mask]\n",
    "\n",
    "  # Saving df_sub\n",
    "  if isprint:\n",
    "      df_sub.to_csv('./' + subname + '.csv')\n",
    "\n",
    "  mrr = score_submissions_no_csv(df_sub, df_gt, get_reciprocal_ranks)\n",
    "  return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A9U77CYCbY8C"
   },
   "outputs": [],
   "source": [
    "#acc = test_accuracy_optimized(model, df_test, df_gt, test_sessions, test_hotels_window, test_clickout_index, hotel_dict, n_features, max_window, meta_dict, meta_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mm2pX5YGxfhz"
   },
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WruVj91c65nl"
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    " \n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "         \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "               \n",
    "        self.lstm = nn.LSTM(input_size = input_dim, hidden_size = hidden_dim, num_layers = layer_dim)  \n",
    "        \n",
    "        self.hidden_fc = nn.Linear(hidden_dim, hidden_dim * 10)\n",
    "        \n",
    "        #self.hidden_fc2 = nn.Linear(hidden_dim * 10, hidden_dim * 100)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 10, output_dim)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(p=0.2)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(1)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        #print(x.shape,\"x.shape\")100, 28, 28\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(1), self.hidden_dim).cuda()\n",
    "        else:\n",
    "            h0 = torch.zeros(self.layer_dim, x.size(1), self.hidden_dim)\n",
    "\n",
    "        # Initialize cell state\n",
    "        if torch.cuda.is_available():\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(1), self.hidden_dim).cuda()\n",
    "        else:\n",
    "            c0 = torch.zeros(self.layer_dim, x.size(1), hidden_dim)\n",
    "\n",
    "        \n",
    "        #cn = c0[0,:,:]\n",
    "        #hn = h0[0,:,:]\n",
    "\n",
    "        #for seq in range(x.size(1)):\n",
    "        #    hn, cn = self.lstm(x[:,seq,:], (hn,cn)) \n",
    "        #    outs.append(hn)\n",
    "            \n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        #out = self.fc(out)\n",
    "        \n",
    "        out = out[-1, :, :]\n",
    "        \n",
    "        out = F.relu(self.hidden_fc(out))\n",
    "        \n",
    "        #out = F.relu(self.hidden_fc2(out))\n",
    "        \n",
    "        out = self.dropout_layer(out)\n",
    "       \n",
    "        \n",
    "        #out = out[]\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        #out = self.softmax(out)\n",
    "        \n",
    "        #out = self.fc(out) \n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if batchsize == 0:\n",
    "    #this splits the training set sessions into multiple mini-sessions\n",
    "    sessions, categories, hotels_window = prepare_input(df_train)\n",
    "else:\n",
    "    sessions, categories, hotels_window = prepare_input_batched(df_train, batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pv1jW7rPw4D1"
   },
   "outputs": [],
   "source": [
    "test_sessions, test_hotels_window, test_clickout_index = prepare_test(df_test, df_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3R5A5BnfE6zU"
   },
   "outputs": [],
   "source": [
    "max_window = 0\n",
    "for window in hotels_window:\n",
    "  if len(window) > max_window:\n",
    "    max_window = len(window)\n",
    "for window in test_hotels_window:\n",
    "  if len(window) > max_window:\n",
    "    max_window = len(window)\n",
    "max_window = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "4GgAak1lEOo-",
    "outputId": "cc6a05f7-125e-4d72-9303-80e887cc72b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_hotels is 45148\n",
      "n_features_w2vec is 100\n",
      "n_features_impression is 0\n",
      "n_features_prices is 0\n",
      "n_features is 100\n"
     ]
    }
   ],
   "source": [
    "meta_dict = []\n",
    "meta_list = []\n",
    "price_dict = []\n",
    "n_hotels = len(hotel_dict.index2word)\n",
    "n_features_w2vec = len(word2vec.wv['666856'])\n",
    "n_features_impression = max_window\n",
    "n_features_prices = 0\n",
    "n_features = n_features_w2vec + n_features_impression + n_features_prices\n",
    "\n",
    "print('n_hotels is ' + str(n_hotels))\n",
    "print('n_features_w2vec is ' + str(n_features_w2vec))\n",
    "print('n_features_impression is ' + str(n_features_impression))\n",
    "print('n_features_prices is ' + str(n_features_prices))\n",
    "print('n_features is ' + str(n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jUrFBpYQct8Z",
    "outputId": "fd323108-a9b0-43ec-ed4e-1b007bcfedaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_dim is 100\n"
     ]
    }
   ],
   "source": [
    "input_dim = n_features\n",
    "output_dim = n_hotels\n",
    "#hidden_dim = int(1/10 * (input_dim + output_dim))\n",
    "hidden_dim = 100\n",
    "print('hidden_dim is ' + str(hidden_dim))\n",
    "layer_dim = 1\n",
    "n_hidden = hidden_dim\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "model.lstm.weight_hh_l0.data.fill_(0)\n",
    "x = 1\n",
    "nn.init.uniform_(model.fc.weight, -x, x)\n",
    "nn.init.uniform_(model.fc.bias, -x, x)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CqJoiGeLX2bJ"
   },
   "outputs": [],
   "source": [
    "#functions for training phase\n",
    "\n",
    "def session_to_tensor(session, hotels_window, max_window):\n",
    "  tensor = torch.zeros(len(session), 1, n_features)\n",
    "  \n",
    "  for ai, action in enumerate(session):\n",
    "    tensor[ai][0] = hotel_to_tensor(action['reference'], hotel_dict, n_features_w2vec, hotels_window, max_window)\n",
    "  return tensor\n",
    "\n",
    "def sessions_to_batch(session_list, hotel_dict, max_session_len, batch_size, n_features, n_features_w2vec, hotels_window, max_window): #modified\n",
    "\n",
    "  tensor = torch.zeros(max_session_len, batch_size, n_features)\n",
    "  \n",
    "  for si, session in enumerate(session_list):\n",
    "    for ai, action in enumerate(session):\n",
    "      tensor[ai][si] = hotel_to_tensor(action['reference'], hotel_dict, n_features_w2vec, hotels_window, max_window)\n",
    "  return tensor\n",
    "\n",
    "def hotel_to_tensor(hotel, hotel_dict, n_features_w2vec, hotels_window, max_window):\n",
    "  tensor_w2vec = torch.zeros(n_features_w2vec)\n",
    "  tensor_window = torch.zeros(max_window)\n",
    "  tensor_prices = torch.zeros(n_features_prices)\n",
    "  \n",
    "  if hotel in hotel_dict: #-----------int\n",
    "    tensor_w2vec = torch.from_numpy(hotel_dict[hotel])\n",
    "  \n",
    "  if max_window != 0:\n",
    "    if hotel in hotels_window:\n",
    "      tensor_window[hotels_window.index(hotel)] = 1\n",
    "    \n",
    "  if hotel in price_dict:\n",
    "    tensor_prices[price_dict.index(hotel)] = 1\n",
    "      \n",
    "  tensor = torch.cat((tensor_w2vec, tensor_window), 0)\n",
    "  tensor = torch.cat((tensor, tensor_prices), 0)\n",
    "  \n",
    "  return tensor\n",
    "\n",
    "def hotel_to_category(hotel, hotel_dict, n_features):\n",
    "  tensor = torch.zeros(1)\n",
    "\n",
    "  if hotel in hotel_dict.index2word:\n",
    "    tensor = torch.tensor([hotel_dict.index2word.index(hotel)], dtype=torch.long)\n",
    "\n",
    "  \n",
    "  return tensor\n",
    "\n",
    "def hotels_to_category_batch(hotel_list, hotel_dict, n_hotels, batch_size): #modified\n",
    "  tensor = torch.zeros(batch_size)\n",
    "  for hi, hotel in enumerate(hotel_list):\n",
    "    if hotel in hotel_dict.index2word:\n",
    "      tensor[hi] = torch.tensor([hotel_dict.index2word.index(hotel)], dtype=torch.long)\n",
    "  return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rrajJsPWYeg6"
   },
   "outputs": [],
   "source": [
    "def category_from_output(output):\n",
    "  top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data\n",
    "  category_i = int(top_i[0][0])\n",
    "  #print(output)\n",
    "  return hotel_dict.index2word[category_i], category_i\n",
    "  \n",
    "  \n",
    "def list_to_space_string(l):\n",
    "  \"\"\"Return a space separated string from a list\"\"\"\n",
    "  s = \" \".join(l)\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wGJPPZHeYjlc"
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss().cuda()\n",
    "#loss_fn = torch.nn.NLLLoss().cuda()\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(category_tensor, line_tensor):\n",
    "    hidden = torch.zeros(1, 1, n_hidden)\n",
    "    c = torch.zeros(1, 1, n_hidden)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    line_tensor = line_tensor.requires_grad_()\n",
    "    line_tensor = line_tensor.cuda()\n",
    "    \n",
    "\n",
    "    output = model(line_tensor)\n",
    "    \n",
    "    category_tensor = category_tensor.long().cuda()\n",
    "\n",
    "    loss = loss_fn(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4777
    },
    "colab_type": "code",
    "id": "RCdfWVSoYmLz",
    "outputId": "91cd1ec3-24ce-4d92-913f-6042d7e76110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1223 sessions to be computed\n",
      "(0m 5s) 5.2984 1240c5a86d97d / 9 \n",
      "(0m 11s) 5.2155 29e0656479fb7 / 1 \n",
      "(0m 16s) 4.2959 3e8ae94bb6054 / 2 \n",
      "(0m 20s) 6.4385 543f99f78fcf8 / 2 \n",
      "(0m 25s) 6.3694 68b8d95ceffb6 / 1 \n",
      "(0m 30s) 7.5852 7ce8698867bf8 / 3 \n",
      "(0m 35s) 6.6763 91b3799d0a9e4 / 1 \n",
      "(0m 39s) 7.3770 a64f9baca46be / 1 \n",
      "(0m 44s) 7.4391 b9c47e9a8ed5f / 7 \n",
      "(0m 49s) 8.4268 cf0c96d88d2ef / 8 \n",
      "(0m 53s) 9.2293 e397dacb6ce87 / 3 \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "#distance = nn.PairwiseDistance(p=2., eps=1e-6)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "n_iters = len(sessions) * num_epochs\n",
    "print_every = 100\n",
    "plot_every = 1\n",
    "\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "all_acc = []\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  model.train()\n",
    "  iter = 0\n",
    "  \n",
    "  #print('epoch ' + str(epoch))\n",
    "  print(str(len(sessions)) + ' sessions to be computed')\n",
    "  \n",
    "  for index, session in enumerate(sessions):\n",
    "    iter = iter + 1\n",
    "\n",
    "    #ession_tensor = session_to_tensor(session, hotels_window[index], max_window)\n",
    "    #ategory = categories[index]\n",
    "    #ategory_tensor = hotel_to_category(category, hotel_dict, n_hotels)\n",
    "\n",
    "    if batchsize == 0:\n",
    "        session_tensor = session_to_tensor(session, hotel_dict, n_features, n_features_w2vec, hotels_window[index], max_window)  \n",
    "        category = categories[index]\n",
    "        category_tensor = hotel_to_category(category, hotel_dict, n_hotels)\n",
    "    else:\n",
    "        max_session_len = 0\n",
    "        for si, single_session in enumerate(session):\n",
    "            if len(single_session) > max_session_len:\n",
    "                max_session_len = len(single_session)\n",
    "        session_tensor = sessions_to_batch(session, hotel_dict, max_session_len, batchsize, n_features, n_features_w2vec, hotels_window[index], max_window)\n",
    "        category = categories[index]\n",
    "        category_tensor = hotels_to_category_batch(category, hotel_dict, n_hotels, batchsize)\n",
    "    \n",
    "    output, loss = train(category_tensor, session_tensor)\n",
    "\n",
    "    current_loss += loss\n",
    "      \n",
    "    if iter % print_every == 0:\n",
    "\n",
    "        guess, guess_i = category_from_output(output)\n",
    "\n",
    "        correct = '' if guess == category else ' (%s)' % category\n",
    "        print('(%s) %.4f %s / %s %s' % (timeSince(start), loss, session[0][0]['session_id'], guess[0], correct[0]))\n",
    "\n",
    "        \n",
    "  # Add current loss avg to list of losses\n",
    "  if epoch % plot_every == 0:\n",
    "      all_losses.append(current_loss / (plot_every * len(sessions)))\n",
    "      print('Epoch: ' + str(epoch) + ' Loss: ' + str(current_loss / (plot_every * len(sessions))))\n",
    "      print('%d %d%% (%s)' % (epoch, epoch / num_epochs * 100, timeSince(start)))\n",
    "      #acc = test_accuracy(model, df_test, df_gt)\n",
    "      acc = test_accuracy_optimized(model, df_test, df_gt, test_sessions, test_hotels_window, test_clickout_index, hotel_dict, n_features, max_window, meta_dict, meta_list)\n",
    "      print(\"Score: \" + str(acc))\n",
    "      all_acc.append(acc)\n",
    "      current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3026
    },
    "colab_type": "code",
    "id": "xA1twchBaY7A",
    "outputId": "a619e8ca-32a9-45a0-87b3-5c79e8a1c941"
   },
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "I1tpfJ4nuvty",
    "outputId": "ed21be97-6a56-4a28-fe79-54bd438541c1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "b-84Yo6ZV7X2",
    "outputId": "bb1b9e78-d5bf-42dc-d023-20ed2306e682"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "hFFHfxYbMXIy",
    "outputId": "ab62a3fd-c58e-4bd2-a335-4dad36e74a73"
   },
   "outputs": [],
   "source": [
    "test_hotels_window[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "Kr3ArXh2MklK",
    "outputId": "a5418ab2-7157-4544-85f5-8cfd596bd7cf"
   },
   "outputs": [],
   "source": [
    "test_sessions[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "fXEZk2M7eiuY",
    "outputId": "2197e515-7344-4fcb-b87a-19facfaa949e"
   },
   "outputs": [],
   "source": [
    "df_test[df_test['session_id'] == '2423aea8cde50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "mGmMUEPNevh8",
    "outputId": "26c8cfe0-6030-4a51-bb8c-ce4330f1b311"
   },
   "outputs": [],
   "source": [
    "df_meta[df_meta['item_id'] == '2793224']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "31udGv-N6_kj",
    "outputId": "2a2f4c95-2db5-4624-b0fb-238ca513c843"
   },
   "outputs": [],
   "source": [
    "df_gt[df_gt['session_id'] == '2423aea8cde50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "zuFya_bgLzkG",
    "outputId": "256fb235-69ac-43c8-8575-c54788e5658e"
   },
   "outputs": [],
   "source": [
    "df_train[df_train['reference'] == '2793224']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1057
    },
    "colab_type": "code",
    "id": "n8BRGo72L0PG",
    "outputId": "49baf5df-1a5d-4a41-f082-196241101a4b"
   },
   "outputs": [],
   "source": [
    "evaluate_debug(test_sessions[5],hotel_dict, n_features, test_hotels_window[5], max_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "bOksPI9S77-M",
    "outputId": "6dbd22e4-1f68-46b1-94f2-fbc2dee3f543"
   },
   "outputs": [],
   "source": [
    "evaluate_debug_false(test_sessions[5],hotel_dict, n_features, test_hotels_window[5], max_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pvTclC5kPggC",
    "outputId": "7aa772e9-59ea-4bf5-a50e-da532632c6db"
   },
   "outputs": [],
   "source": [
    "acc = test_accuracy_optimized(model, df_test, df_gt, test_sessions, test_hotels_window, test_clickout_index, hotel_dict, n_features, max_window, meta_dict, meta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "32tYAekWP87N",
    "outputId": "03a53905-2674-4f0d-fd68-5a52a1eeae7c"
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1397
    },
    "colab_type": "code",
    "id": "5flC3nhM8TwR",
    "outputId": "e3d308e6-7450-40b5-d0bf-4c3be8485908"
   },
   "outputs": [],
   "source": [
    "acc = test_accuracy_optimized_false(model, df_test, df_gt, test_sessions, test_hotels_window, test_clickout_index, hotel_dict, n_features, max_window, meta_dict, meta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v9rWVx858Tyu",
    "outputId": "807c3b97-5363-4bb2-d0aa-f9f9f43a2b7c"
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "PLE0JrjKLWxX",
    "outputId": "9ea36cc6-51f3-46ef-a4c6-cba601cfc546"
   },
   "outputs": [],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3451
    },
    "colab_type": "code",
    "id": "8TTDXDCv5_wA",
    "outputId": "b8a9f5b7-58ff-4057-b24d-80f3cc1096bc"
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3026
    },
    "colab_type": "code",
    "id": "jT1LDX3RO2Ay",
    "outputId": "8cc3c81b-8c05-433b-cdbc-a071c300fc66"
   },
   "outputs": [],
   "source": [
    "df_test[df_test['item_recommendations'] != np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XRgdGEbzk4p_",
    "outputId": "2382cdab-8fe3-4c55-805d-3d18ce2cc20f"
   },
   "outputs": [],
   "source": [
    "#mrr = score_submissions_no_csv(df_sub, df_gt, get_reciprocal_ranks)\n",
    "mrr = acc = test_accuracy_optimized(model, df_test, df_gt, test_sessions, test_hotels_window, test_clickout_index, hotel_dict, n_features, max_window, meta_dict, meta_list)\n",
    "print(\"End execution with score \" + str(mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3qAqD0u8Mge"
   },
   "outputs": [],
   "source": [
    "df_temp = df_test[df_test['user_id'] == '68Q297NAT23H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "colab_type": "code",
    "id": "q2kdCjN08fv1",
    "outputId": "d26872a5-a02e-4f7a-e339-e7e30123135d"
   },
   "outputs": [],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQ72mIlz8m3b"
   },
   "outputs": [],
   "source": [
    "df_temp = df_temp.drop(df_temp[df_temp['step'] == 3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "SPTQ68fo89dx",
    "outputId": "81f5160b-3834-4482-fdf7-02c63f2c2bbf"
   },
   "outputs": [],
   "source": [
    "test_accuracy(df_temp, df_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WXPTsRre9oC2"
   },
   "outputs": [],
   "source": [
    "session = []\n",
    "hotel_window = []\n",
    "for action_i, action in df_temp.iterrows():\n",
    "  if (action['action_type'] == 'clickout item') & math.isnan(float(action['reference'])):\n",
    "    hotel_window = action['impressions'].split('|')\n",
    "  session.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "El8RBsiuuX-6"
   },
   "outputs": [],
   "source": [
    "#importing training\n",
    "link_train = 'https://drive.google.com/open?id=1zCpgAT-RGtMYDnhv8KHRsFc8NONKz55r'\n",
    "fluff, id_train = link_train.split('=')\n",
    "downloaded = drive.CreateFile({'id':id_train}) \n",
    "downloaded.GetContentFile('train_100.csv')\n",
    "\n",
    "df_train_100 = pd.read_csv(\"./train_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj5anQ8JwHyX"
   },
   "outputs": [],
   "source": [
    "df_train_100 = remove_single_actions(df_train_100)\n",
    "df_train_100 =  remove_nonitem_actions(df_train_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lpASNWcj_SwL"
   },
   "outputs": [],
   "source": [
    "#importing test set\n",
    "link_test = 'https://drive.google.com/open?id=1bIWb7rWQecLuyZKW0YP4yDuehD4zgVDg'\n",
    "fluff, id_test = link_test.split('=')\n",
    "downloaded = drive.CreateFile({'id':id_test}) \n",
    "downloaded.GetContentFile('test_100.csv')\n",
    "\n",
    "df_test_100 = pd.read_csv(\"./test_100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "560yjD2PwLBJ"
   },
   "outputs": [],
   "source": [
    "df_test_100 = remove_single_actions(df_test_100)\n",
    "df_test_100 = remove_nonitem_actions(df_test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtKcJWqrrqER"
   },
   "outputs": [],
   "source": [
    "#importing meta\n",
    "link_test = 'https://drive.google.com/open?id=1Qzu75vrXcfB0SjbtcKJzVKoZJht6vUHT'\n",
    "fluff, id_test = link_test.split('=')\n",
    "downloaded = drive.CreateFile({'id':id_test}) \n",
    "downloaded.GetContentFile('item_meta.csv')\n",
    "\n",
    "df_meta = pd.read_csv(\"./item_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8L_lBqH3vxZs"
   },
   "outputs": [],
   "source": [
    "df_test[df_test['action_type'] == 'clickout item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "soi9UY7qrk0B"
   },
   "outputs": [],
   "source": [
    "df_test_off[df_test_off['user_id'] == 'ZVTSO44R1US2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qaWQbyQsmMw"
   },
   "outputs": [],
   "source": [
    "action = df_test_off[(df_test_off['user_id'] == 'ZVTSO44R1US2') & (df_test_off['step'] == 49)]\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7V2KI1svM2p"
   },
   "outputs": [],
   "source": [
    "action['impressions'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--iP4hIauxhM"
   },
   "outputs": [],
   "source": [
    "for item_id in action['impressions'].values[0].split():\n",
    "  print(df_meta[df_meta['item_id'] == item_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NU7coIdduVSk"
   },
   "outputs": [],
   "source": [
    "df_meta[df_meta['item_id'] == '4775012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RVOlCZ76vejN"
   },
   "outputs": [],
   "source": [
    "hotels_ref = []\n",
    "hotels_full = []\n",
    "for action_index, action in df_train_100.iterrows():\n",
    "  hotels_ref.append(action['reference'])\n",
    "  hotels_full.append(action['reference'])\n",
    "  if action['action_type'] == 'clickout item':\n",
    "      hotels_full = hotels_full + action['impressions'].split('|')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtaspNeyw2aY"
   },
   "outputs": [],
   "source": [
    "hotels_ref = list(set(hotels_ref))\n",
    "hotels_full = list(set(hotels_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eea_-dGnw91D"
   },
   "outputs": [],
   "source": [
    "len(hotels_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyaYUjMew_DU"
   },
   "outputs": [],
   "source": [
    "len(hotels_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JKHT0W1yydI"
   },
   "outputs": [],
   "source": [
    "for action_index, action in df_test_100.iterrows():\n",
    "  hotels_ref.append(action['reference'])\n",
    "  hotels_full.append(action['reference'])\n",
    "  if action['action_type'] == 'clickout item':\n",
    "      hotels_full = hotels_full + action['impressions'].split('|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntilVXQq4A5V"
   },
   "source": [
    "TEST PRICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "paPRcnTn4hQ_"
   },
   "outputs": [],
   "source": [
    "#importing prices\n",
    "link_test = 'https://drive.google.com/open?id=1Y0BtPk-Bp5tTYMMwl11fvjYeo6lqDqm0'\n",
    "fluff, id_test = link_test.split('=')\n",
    "downloaded = drive.CreateFile({'id':id_test}) \n",
    "downloaded.GetContentFile('item_price.csv')\n",
    "\n",
    "df_prices = pd.read_csv(\"./item_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUwTNz9X4Aei"
   },
   "outputs": [],
   "source": [
    "def generate_prices_sparse_matrix(df, features_col='intervals'):\n",
    "    df['present'] = 1\n",
    "    hotel_dict = create_item_dict(df) #Controllare che sia uguale all'altro dizionario\n",
    "    feature_dict = create_item_dict(df, col_name='feature')\n",
    "    list_hotel = list(df['reference'])\n",
    "    list_features = list(df['feature'])\n",
    "    list_data = list(df['present'])\n",
    "    n_items = len(list_hotel)\n",
    "    n_features = len(list_features)\n",
    "    # Convert each list of string in a list of indexes\n",
    "    list_items = list(map(lambda x: hotel_dict[x], list_hotel))\n",
    "    list_features = list(map(lambda x: feature_dict[x], list_features))\n",
    "    # Generate the sparse matrix\n",
    "    row = np.array(list_items)\n",
    "    col = np.array(list_features)\n",
    "    data = np.array(list_data)\n",
    "    csr = csr_matrix((data, (row, col)), shape=(n_items, n_features))\n",
    "\n",
    "    return csr, hotel_dict\n",
    "  \n",
    "def get_hotel_prices(df_metadata, n_categories = 2000):\n",
    "    \"\"\"\n",
    "    Required Input -\n",
    "        - metadata_file = file with the average price for each hotel\n",
    "    \"\"\"\n",
    "    #print(\"Reading metadata: \" + metadata_file)\n",
    "    df_metadata['price'] = df_metadata['price'].apply(lambda x: math.log10(x))\n",
    "    # Define the range\n",
    "    max_price = df_metadata['price'].max()\n",
    "    min_price = df_metadata['price'].min()\n",
    "    range = (max_price - min_price) / n_categories\n",
    "    # Generate the classes\n",
    "    df_metadata['intervals'] = pd.cut(df_metadata['price'], bins=np.arange(min_price,max_price,range))\n",
    "    df_metadata.loc[:, 'intervals'] = df_metadata['intervals'].apply(str)\n",
    "    #classes_dic = create_user_dict(df_metadata, col_name = 'intervals')\n",
    "    #df_metadata.loc[:, 'intervals'] = df_metadata['intervals'].apply(lambda x : classes_dic.get(x))\n",
    "    #df_metadata.loc[:, 'intervals'] = df_metadata['intervals'].apply(int)\n",
    "    # Create a dictionary of item_id -> price_category\n",
    "    price_dic = pd.Series(df_metadata.intervals.values,index=df_metadata.impressions).to_dict()\n",
    "\n",
    "\n",
    "    return price_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6d6jceKX54yG"
   },
   "outputs": [],
   "source": [
    "df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUQwaDXY4E5W"
   },
   "outputs": [],
   "source": [
    "price_dic = get_hotel_prices(df_prices, n_categories = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Elq-uwZP5h-d"
   },
   "outputs": [],
   "source": [
    "price_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hF28WIYn6Qjk"
   },
   "outputs": [],
   "source": [
    "len(price_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IfHt8YsI6cZK"
   },
   "outputs": [],
   "source": [
    "len(list(set(price_dic.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1lGjecX3UFid"
   },
   "outputs": [],
   "source": [
    "def test_accuracy_optimized(model, df_test, df_gt, sessions, hotels_window, clickout_index, hotel_dict, n_features, max_window, meta_dict, meta_list, subname=\"submission_default_name\", isprint=False):\n",
    "  \"\"\"Return the score obtained by the net on the test dataframe\"\"\"\n",
    "\n",
    "  test_dim = len(df_test)\n",
    "\n",
    "  print_every = 500\n",
    "\n",
    "  missed = 0\n",
    "  \n",
    "  missed_target = 0\n",
    "\n",
    "  for session_index, session in enumerate(sessions):\n",
    "    if clickout_index[session_index] != []:\n",
    "      df_test.loc[clickout_index[session_index], 'item_recommendations'] = evaluate(session, hotel_dict, n_features, hotels_window[session_index], max_window)\n",
    "      #print(df_gt[(df_gt['session_id'] == df_test.loc[clickout_index[session_index], 'session_id'].values[0]) & (df_gt['step'] == df_test.loc[clickout_index[session_index], 'step'].values[0])]['reference'].values[0])\n",
    "      #target = df_gt[(df_gt['session_id'] == df_test.loc[clickout_index[session_index], 'session_id'].values[0]) & (df_gt['step'] == df_test.loc[clickout_index[session_index], 'step'].values[0])]['reference'].values[0]\n",
    "      #print(type(target))\n",
    "      #if int(target) not in hotel_dict: \n",
    "        #missed_target = missed_target + 1\n",
    "        #print(session_index)\n",
    "  df_sub = get_submission_target(df_test)\n",
    "\n",
    "  #print(str(missed_target) + ' correct hotels were not in dictionary - total: ' + str(len(hotels_window)))\n",
    "  \n",
    "  #Removing unnecessary columns\n",
    "  df_sub = df_sub[['user_id', 'session_id', 'timestamp','step', 'item_recommendations']]\n",
    "\n",
    "  mask = df_sub[\"item_recommendations\"].notnull()\n",
    "  df_sub = df_sub[mask]\n",
    "\n",
    "  # Saving df_sub\n",
    "  if isprint:\n",
    "      df_sub.to_csv('./' + subname + '.csv')\n",
    "\n",
    "  mrr = score_submissions_no_csv(df_sub, df_gt, get_reciprocal_ranks)\n",
    "  return mrr, df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGQGk6ImWPb4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzEeHFwMUZNE"
   },
   "outputs": [],
   "source": [
    "mrr, df_sub_rnn = test_accuracy_optimized(model, df_test, df_gt, test_sessions, test_hotels_window, test_clickout_index, hotel_dict, n_features, max_window, meta_dict, meta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XWvSu20jUipf",
    "outputId": "8404a584-bf83-4778-e4ec-0ea0a2b43871"
   },
   "outputs": [],
   "source": [
    "mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "m_mYeQSgUjnh",
    "outputId": "b6de6e19-b783-4c7a-de99-58b6386dfe9c"
   },
   "outputs": [],
   "source": [
    "df_sub_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nJte4gD8VGcL"
   },
   "outputs": [],
   "source": [
    "test_clickout_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtLK5XFQVH50"
   },
   "outputs": [],
   "source": [
    "test_accuracy(model, df_test, df_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-qVjp9UZpKjF",
    "outputId": "551a7d06-5b45-4525-f432-3a9b1aea6921"
   },
   "outputs": [],
   "source": [
    "df_test['item_recommendations'] = np.nan\n",
    "\n",
    "test_dim = len(df_test)\n",
    "temp_session = []\n",
    "hotels_window = []\n",
    "i = 0\n",
    "print_every = 500\n",
    "step = 0\n",
    "    \n",
    "for action_index, action in df_test.iterrows():    \n",
    "    if(action['reference'] != 'unknown'):\n",
    "        if (action['action_type'] == 'clickout item') & math.isnan(float(action['reference'])):\n",
    "            hotels_window = action['impressions'].split('|')\n",
    "\n",
    "            if len(temp_session) != 0:\n",
    "                df_test.loc[action_index, 'item_recommendations'] = list_to_space_string(action['impressions'].split('|'))\n",
    "\n",
    "            temp_session.append(action)\n",
    "\n",
    "        else:\n",
    "            temp_session.append(action)\n",
    "\n",
    "    if(i < test_dim-1):\n",
    "        if action['session_id'] != df_test.iloc[[i + 1]]['session_id'].values[0]:\n",
    "            step = 0\n",
    "            #print(temp_session)\n",
    "            #print(hotels_window)\n",
    "            #print(p.r)\n",
    "            temp_session = []\n",
    "            hotels_window = []\n",
    "\n",
    "    i = i+1  \n",
    "    step = step + 1\n",
    "\n",
    "\n",
    "df_sub = get_submission_target(df_test)\n",
    "\n",
    "#Removing unnecessary columns\n",
    "df_sub = df_sub[['user_id', 'session_id', 'timestamp','step', 'item_recommendations']]\n",
    "\n",
    "for action_index, action in df_gt.iterrows():\n",
    "    if action_index not in df_sub.index.values.tolist():\n",
    "        df_gt = df_gt.drop(action_index)\n",
    "\n",
    "mask = df_sub[\"item_recommendations\"].notnull()\n",
    "df_sub_impression = df_sub[mask]\n",
    "\n",
    "mrr = score_submissions_no_csv(df_sub, df_gt, get_reciprocal_ranks)\n",
    "print(mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "tElbktWnoe9P",
    "outputId": "bf9c0716-8cb8-4699-d7cf-d61e6625b6af"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import operator\n",
    "import math\n",
    "\n",
    "MERGE_COLS = [\"user_id\", \"session_id\", \"timestamp\", \"step\"]\n",
    "\n",
    "def generate_rranks_range(start, end):\n",
    "    \"\"\"Generate reciprocal ranks for a given list length.\"\"\"\n",
    "\n",
    "    return 1.0 / (np.arange(start, end) + 1)\n",
    "\n",
    "def read_into_df(file):\n",
    "    \"\"\"Read csv file into data frame.\"\"\"\n",
    "    df = (\n",
    "        pd.read_csv(file)\n",
    "            .set_index(['user_id', 'session_id', 'timestamp', 'step'])\n",
    "    )\n",
    "\n",
    "    return df\n",
    "def score_submissions(subm_csv, gt_csv, objective_function):\n",
    "    \"\"\"Score submissions with given objective function.\"\"\"\n",
    "\n",
    "    print(f\"Reading ground truth data {gt_csv} ...\")\n",
    "    df_gt = read_into_df(gt_csv)\n",
    "\n",
    "    print(f\"Reading submission data {subm_csv} ...\")\n",
    "    df_subm = read_into_df(subm_csv)\n",
    "    print('Submissions')\n",
    "    print(df_subm.head(10))\n",
    "    # create dataframe containing the ground truth to target rows\n",
    "    cols = ['reference', 'impressions', 'prices']\n",
    "    df_key = df_gt.loc[:, cols]\n",
    "\n",
    "    # append key to submission file\n",
    "    df_subm_with_key = df_key.join(df_subm, how='inner')\n",
    "    print(df_subm_with_key.head())\n",
    "    df_subm_with_key.reference = df_subm_with_key.reference.astype(int)\n",
    "    df_subm_with_key = convert_string_to_list(\n",
    "        df_subm_with_key, 'item_recommendations', 'item_recommendations'\n",
    "    )\n",
    "\n",
    "    # score each row\n",
    "    df_subm_with_key['score'] = df_subm_with_key.apply(objective_function, axis=1)\n",
    "    df_subm_with_key.to_csv('borda.csv')\n",
    "    print(df_subm_with_key)\n",
    "    mrr = df_subm_with_key.score.mean()\n",
    "\n",
    "    return mrr\n",
    "\n",
    "def get_reciprocal_ranks(ps):\n",
    "    \"\"\"Calculate reciprocal ranks for recommendations.\"\"\"\n",
    "    mask = ps.reference == np.array(ps.item_recommendations)\n",
    "\n",
    "    if mask.sum() == 1:\n",
    "        rranks = generate_rranks_range(0, len(ps.item_recommendations))\n",
    "        return np.array(rranks)[mask].min()\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def convert_string_to_list(df, col, new_col):\n",
    "    \"\"\"Convert column from string to list format.\"\"\"\n",
    "    fxn = lambda arr_string: [int(item) for item in str(arr_string).split(\" \")]\n",
    "\n",
    "    mask = ~(df[col].isnull())\n",
    "\n",
    "    df[new_col] = df[col]\n",
    "    df.loc[mask, new_col] = df[mask][col].map(fxn)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_single_list_score(l):\n",
    "    \"\"\"\n",
    "        Input -> list of string\n",
    "        Output -> Dictionary {'item': score}\n",
    "    \"\"\"\n",
    "    score_dic = {}\n",
    "    i = 0\n",
    "    for rec in l:\n",
    "        score_dic[rec] = len(l) - i\n",
    "        i = i + 1\n",
    "    return score_dic\n",
    "\n",
    "def sum_and_sort_dictionaries(dic_1, dic_2):\n",
    "    \"\"\"\n",
    "        Input -> 2 dictionaries\n",
    "        Output -> 1 list of item sorted by score\n",
    "    \"\"\"\n",
    "    sum_dic = dict(Counter(dic_1)+Counter(dic_2))\n",
    "    sorted_x = sorted(sum_dic.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    sorted_items = list(map(lambda x:x[0], sorted_x))\n",
    "    return sorted_items\n",
    "\n",
    "def calculate_borda(mf_rec, rnn_rec):\n",
    "    if(mf_rec == ''):\n",
    "        return rnn_rec\n",
    "    if(rnn_rec == ''):\n",
    "        return mf_rec\n",
    "\n",
    "    # Calculate score dictionary for mf\n",
    "    mf_rec_dic = calculate_single_list_score(mf_rec.split(' '))\n",
    "    rnn_rec_dic = calculate_single_list_score(rnn_rec.split(' '))\n",
    "    list_items = sum_and_sort_dictionaries(mf_rec_dic, rnn_rec_dic)\n",
    "    result = \" \".join(list_items)\n",
    "    return result\n",
    "\n",
    "df_mf = df_sub_impression\n",
    "df_rnn = df_sub_rnn\n",
    "gt_file = 'gt.csv'\n",
    "submission_file = 'submission_ensamble.csv'\n",
    "\n",
    "\n",
    "df_merged = (\n",
    "    df_mf\n",
    "    .merge(df_rnn,suffixes=('_mf', '_rnn'),\n",
    "           left_on=MERGE_COLS,\n",
    "           right_on=MERGE_COLS,\n",
    "           how=\"left\")\n",
    "    )\n",
    "#print(df_merged)\n",
    "df_merged = df_merged.fillna('')\n",
    "#print(df_merged)\n",
    "df_merged['item_recommendations'] = df_merged.apply(lambda x: calculate_borda(x.item_recommendations_mf, x.item_recommendations_rnn), axis=1)\n",
    "df_merged = df_merged[MERGE_COLS + ['item_recommendations']]\n",
    "df_merged.to_csv(submission_file)\n",
    "mrr =score_submissions(submission_file, gt_file, get_reciprocal_ranks)\n",
    "#print(df_merged.head())\n",
    "print('Score: ' + str(mrr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTjRE56PpAIk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM(50h)_w2vec+order_learn0,001_50ep_nohiddenfc.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
